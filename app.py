import io, datetime as dt, pandas as pd, streamlit as st
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import insert as pg_insert
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import altair as alt

# ---------- Streamlit åŸºæœ¬ ----------
st.set_page_config(page_title="Slot Manager", layout="wide")

# ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¢ãƒ¼ãƒ‰é¸æŠ ----------
mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰", ("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿", "ğŸ“Š å¯è¦–åŒ–"))

st.title("ğŸ° Slot Data Manager & Visualizer")

# ---------- Secrets ----------
SA_INFO = st.secrets["gcp_service_account"]
PG_CFG  = st.secrets["connections"]["slot_db"]

# ---------- Google Drive ----------
@st.cache_resource
def gdrive():
    creds = Credentials.from_service_account_info(
        SA_INFO, scopes=["https://www.googleapis.com/auth/drive.readonly"])
    return build("drive", "v3", credentials=creds)
drive = gdrive()

# ---------- Postgres ----------
@st.cache_resource
def engine():
    url = (f"postgresql+psycopg2://{PG_CFG.username}:{PG_CFG.password}"
           f"@{PG_CFG.host}:{PG_CFG.port}/{PG_CFG.database}?sslmode=require")
    return sa.create_engine(url, pool_pre_ping=True)
eng = engine()

# ---------- COLUMN_MAP, list_csv_recursive, normalize, ensure_store_table, parse_meta ----------
# (â€» æ—¢å­˜ã®é–¢æ•°ã¯å¤‰æ›´ãªã—ã§ãã®ã¾ã¾è²¼ã‚Šä»˜ã‘)
# ... <ä¸­ç•¥: å‰ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®é–¢æ•°ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãã®ã¾ã¾ä¿æŒ> ...

# ========== å–ã‚Šè¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ ==========
if mode == "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿":
    st.header("Google Drive â†’ Postgres ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    folder_id = st.text_input("Google Drive ãƒ•ã‚©ãƒ«ãƒ€ ID")
    col_s, col_e = st.columns(2)
    import_start = col_s.date_input("å–ã‚Šè¾¼ã¿é–‹å§‹æ—¥", value=dt.date(2025, 1, 1))
    import_end   = col_e.date_input("å–ã‚Šè¾¼ã¿çµ‚äº†æ—¥", value=dt.date.today())

    if st.button("ğŸš€ å–ã‚Šè¾¼ã¿å®Ÿè¡Œ") and folder_id:
        files = [f for f in list_csv_recursive(folder_id)
                 if import_start <= parse_meta(f["path"])[2] <= import_end]
        st.write(f"ğŸ” å¯¾è±¡ CSV: {len(files)} ä»¶")
        bar = st.progress(0.0)
        for i, f in enumerate(files, 1):
            raw = drive.files().get_media(fileId=f["id"]).execute()
            df_raw = pd.read_csv(io.BytesIO(raw), encoding="shift_jis")
            store, machine, date = parse_meta(f["path"])
            if store not in COLUMN_MAP:
                st.warning(f"ãƒãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©: {store} ã‚’ã‚¹ã‚­ãƒƒãƒ—"); continue
            table = ensure_store_table(store)
            df = normalize(df_raw, store)
            df["æ©Ÿç¨®"], df["date"] = machine, date
            valid = set(table.c.keys())
            df = df[[c for c in df.columns if c in valid]]
            if df.empty: continue
            stmt = (pg_insert(table).values(df.to_dict("records")).on_conflict_do_nothing())
            with eng.begin() as conn:
                conn.execute(stmt)
            bar.progress(i/len(files))
        st.success("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")

# ========== å¯è¦–åŒ–ãƒ¢ãƒ¼ãƒ‰ ==========
if mode == "ğŸ“Š å¯è¦–åŒ–":
    st.header("DB å¯è¦–åŒ– & é›†è¨ˆ")
    # åº—èˆ—ãƒªã‚¹ãƒˆå–å¾—
    with eng.connect() as conn:
        stores = [r[0] for r in conn.execute(sa.text(
            "SELECT tablename FROM pg_tables WHERE tablename LIKE 'slot_%'"))]

    if not stores:
        st.info("ã¾ãšå–ã‚Šè¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")
        st.stop()

    store_sel = st.selectbox("åº—èˆ—", stores)
    tbl = sa.Table(store_sel, sa.MetaData(), autoload_with=eng)

    # æ—¥ä»˜ãƒ¬ãƒ³ã‚¸
    d1, d2 = st.columns(2)
    vis_start = d1.date_input("è¡¨ç¤ºé–‹å§‹æ—¥", value=dt.date(2025, 1, 1))
    vis_end   = d2.date_input("è¡¨ç¤ºçµ‚äº†æ—¥", value=dt.date.today())

    # ãƒ‡ãƒ¼ã‚¿å–å¾—
    sql = sa.select(tbl).where(tbl.c.date.between(vis_start, vis_end))
    df_show = pd.read_sql(sql, eng)

    if df_show.empty:
        st.warning("è©²å½“æœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        st.stop()

    # ---------- ç°¡æ˜“ã‚µãƒãƒªãƒ¼ ----------
    st.subheader("ğŸ“Š ã‚µãƒãƒªãƒ¼")
    col_a, col_b = st.columns(2)
    col_a.metric("å¹³å‡åˆæˆç¢ºç‡", f"{df_show['åˆæˆç¢ºç‡'].mean():.3%}")
    col_b.metric("ç·BBå›æ•°", int(df_show['BBå›æ•°'].sum()))

    # ---------- æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ• ----------
    st.subheader("ğŸ“ˆ åˆæˆç¢ºç‡ï¼ˆå°ç•ªå·åˆ¥ï¼‰")
    df_line = df_show.pivot(index="date", columns="å°ç•ªå·", values="åˆæˆç¢ºç‡")
    st.line_chart(df_line)

    # ---------- ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ— ----------
    st.subheader("ğŸ—ºï¸ æ—¥ä»˜Ã—å°ç•ªå· ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆBBå›æ•°ï¼‰")
    heat = alt.Chart(df_show).mark_rect().encode(
        x="date:T",
        y="å°ç•ªå·:O",
        color=alt.Color("BBå›æ•°:Q", scale=alt.Scale(scheme="greenblue")),
        tooltip=["date", "å°ç•ªå·", "BBå›æ•°"]
    ).properties(height=400)
    st.altair_chart(heat, use_container_width=True)
