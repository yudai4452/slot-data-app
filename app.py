import io, datetime as dt, pandas as pd, streamlit as st
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import insert as pg_insert
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import altair as alt

# ---------- Streamlit åŸºæœ¬ ----------
st.set_page_config(page_title="Slot Manager", layout="wide")

# ---------- ã‚µã‚¤ãƒ‰ãƒãƒ¼: ãƒ¢ãƒ¼ãƒ‰é¸æŠ ----------
mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰", ("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿", "ğŸ“Š å¯è¦–åŒ–"))

st.title("ğŸ° Slot Data Manager & Visualizer")

# ---------- Secrets ----------
SA_INFO = st.secrets["gcp_service_account"]
PG_CFG  = st.secrets["connections"]["slot_db"]

# ---------- Google Drive ----------
@st.cache_resource
def gdrive():
    creds = Credentials.from_service_account_info(
        SA_INFO, scopes=["https://www.googleapis.com/auth/drive.readonly"])
    return build("drive", "v3", credentials=creds)
drive = gdrive()

# ---------- Postgres ----------
@st.cache_resource
def engine():
    url = (f"postgresql+psycopg2://{PG_CFG.username}:{PG_CFG.password}"
           f"@{PG_CFG.host}:{PG_CFG.port}/{PG_CFG.database}?sslmode=require")
    return sa.create_engine(url, pool_pre_ping=True)
eng = engine()

# ---------- åº—èˆ—ã”ã¨ã®åˆ—åãƒãƒƒãƒ”ãƒ³ã‚° ----------
COLUMN_MAP = {
    "ãƒ¡ãƒƒã‚»æ­¦è”µå¢ƒ": {
        "å°ç•ªå·":"å°ç•ªå·","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ",
        "BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°","ARTå›æ•°":"ARTå›æ•°","æœ€å¤§æŒã¡ç‰":"æœ€å¤§æŒç‰",
        "BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","ARTç¢ºç‡":"ARTç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ",
    },
    "ã‚¸ãƒ£ãƒ³ã‚¸ãƒ£ãƒ³ãƒãƒ¼ãƒ«ã‚´ãƒƒãƒˆåˆ†å€æ²³åŸ":{
        "å°ç•ªå·":"å°ç•ªå·","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ","BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°",
        "æœ€å¤§æŒã¡ç‰":"æœ€å¤§æŒç‰","BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°",
    },
    "ãƒ—ãƒ¬ã‚´ç«‹å·":{
        "å°ç•ªå·":"å°ç•ªå·","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ","BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°",
        "æœ€å¤§å·®ç‰":"æœ€å¤§å·®ç‰","BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°",
    },
}

# ---------- UTILS ----------
def list_csv_recursive(folder_id: str):
    """ã‚µãƒ–ãƒ•ã‚©ãƒ«ãƒ€ã‚’å«ã‚ .csv ã‚’åˆ—æŒ™ã— 'path' ã‚’ä»˜ã‘ã‚‹"""
    all_files, queue = [], [(folder_id, "")]          # (folder_id, ç¾åœ¨ã®ãƒ‘ã‚¹)
    while queue:
        fid, cur = queue.pop()
        res = drive.files().list(
            q=f"'{fid}' in parents and trashed=false",
            fields="files(id,name,mimeType)",
            pageSize=1000, supportsAllDrives=True).execute()
        for f in res.get("files", []):
            if f["mimeType"] == "application/vnd.google-apps.folder":
                queue.append((f["id"], f"{cur}/{f['name']}"))
            elif f["name"].lower().endswith(".csv"):
                all_files.append({**f, "path": f"{cur}/{f['name']}"})  # â˜…ã“ã“â˜…
    return all_files


def normalize(df_raw: pd.DataFrame, store: str) -> pd.DataFrame:
    """åˆ—åã‚’çµ±ä¸€ã—ã€ç¢ºç‡åˆ—ã‚’ 0â€‘1 ã«æ•´å½¢ã€‚åˆ†æ¯ã ã‘æ¥ã‚‹ 113.0 ã‚‚å¯¾å¿œã€‚"""
    df = df_raw.rename(columns=COLUMN_MAP[store])

    prob_cols = ["BBç¢ºç‡", "RBç¢ºç‡", "ARTç¢ºç‡", "åˆæˆç¢ºç‡"]
    for col in prob_cols:
        if col not in df.columns:
            continue
        ser = df[col].astype(str)
        mask_div = ser.str.contains("/")

        # "1/n" â†’ 1/n (1/0 ã¯ 0)
        if mask_div.any():
            denom = ser[mask_div].str.split("/", expand=True)[1].astype(float)
            df.loc[mask_div, col] = denom.where(denom != 0, pd.NA).rdiv(1.0).fillna(0)

        # å°æ•° or åˆ†æ¯ã ã‘
        num = pd.to_numeric(ser[~mask_div], errors="coerce")
        mask_gt1 = num > 1
        num.loc[mask_gt1] = 1.0 / num.loc[mask_gt1]  # 113.0 â†’ 1/113
        df.loc[~mask_div, col] = num
        df[col] = df[col].astype(float)

    # â¸ æ•´æ•°åˆ—ã‚’ Int64 å‹ã§æ•´å½¢
    int_cols = [
        "å°ç•ªå·", "ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ", "ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°",
        "BBå›æ•°", "RBå›æ•°", "ARTå›æ•°",
        "æœ€å¤§æŒã¡ç‰", "æœ€å¤§å·®ç‰", "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ",
    ]
    for col in int_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").astype("Int64")

    return df

def ensure_store_table(store: str):
    safe = "slot_" + store.replace(" ", "_")
    meta = sa.MetaData()
    if not eng.dialect.has_table(eng.connect(), safe):
        cols = [
            sa.Column("date", sa.Date),
            sa.Column("æ©Ÿç¨®", sa.Text),
        ]
        for col in COLUMN_MAP[store].values():
            cols.append(sa.Column(col, sa.Double, nullable=True))
        cols.append(sa.PrimaryKeyConstraint("date", "æ©Ÿç¨®", "å°ç•ªå·"))
        sa.Table(safe, meta, *cols)
        meta.create_all(eng)
    return sa.Table(safe, meta, autoload_with=eng)

def parse_meta(path: str):
    # ä¾‹: ãƒ‡ãƒ¼ã‚¿/ãƒ¡ãƒƒã‚»æ­¦è”µå¢ƒ/ãƒã‚¤ã‚¸ãƒ£ã‚°ãƒ©ãƒ¼V/slot_machine_data_2025-07-19.csv
    parts = path.strip("/").split("/")
    if len(parts) < 3:
        raise ValueError(f"path å½¢å¼ãŒæƒ³å®šå¤–: {path}")
    store, machine = parts[-3], parts[-2]
    date = dt.date.fromisoformat(parts[-1][-14:-4])
    return store, machine, date

# ========================= å–ã‚Šè¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ =========================
if mode == "ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿":
    st.header("Google Drive â†’ Postgres ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")

    # --- ãƒ•ã‚©ãƒ«ãƒ€ & æ—¥ä»˜ãƒ¬ãƒ³ã‚¸å…¥åŠ› ---------------------------------
    folder_id = st.text_input("Google Drive ãƒ•ã‚©ãƒ«ãƒ€ ID")
    c1, c2 = st.columns(2)
    imp_start = c1.date_input("é–‹å§‹æ—¥", value=dt.date(2025, 1, 1))
    imp_end   = c2.date_input("çµ‚äº†æ—¥", value=dt.date.today())

    # --- å–ã‚Šè¾¼ã¿ãƒœã‚¿ãƒ³ ---------------------------------------------
    if st.button("ğŸš€ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ", disabled=not folder_id):
        # â‘  Drive ã‚’èµ°æŸ»ã—ã¦æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿
        files = [f for f in list_csv_recursive(folder_id)
                 if imp_start <= parse_meta(f["path"])[2] <= imp_end]
        st.write(f"ğŸ” å¯¾è±¡ CSV: **{len(files)} ä»¶**")

        bar = st.progress(0.0)
        for i, f in enumerate(files, 1):
            # â‘¡ CSV ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            raw = drive.files().get_media(fileId=f["id"]).execute()
            df_raw = pd.read_csv(io.BytesIO(raw), encoding="shift_jis", errors="skip")

            # â‘¢ ãƒ¡ã‚¿æƒ…å ±æŠ½å‡º
            store, machine, date = parse_meta(f["path"])
            if store not in COLUMN_MAP:
                st.warning(f"ãƒãƒƒãƒ”ãƒ³ã‚°æœªå®šç¾©: {store} â†’ ã‚¹ã‚­ãƒƒãƒ—"); continue

            # â‘£ æ­£è¦åŒ– & ãƒ†ãƒ¼ãƒ–ãƒ«ç¢ºä¿
            table = ensure_store_table(store)
            df = normalize(df_raw, store)
            df["æ©Ÿç¨®"], df["date"] = machine, date
            df = df[[c for c in df.columns if c in table.c.keys()]]
            if df.empty:
                continue

            # â‘¤ UPSERT
            stmt = (
                pg_insert(table)
                .values(df.to_dict("records"))
                .on_conflict_do_nothing()
            )
            with eng.begin() as conn:
                conn.execute(stmt)

            bar.progress(i / len(files))

        st.success("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")

# ========================= å¯è¦–åŒ–ãƒ¢ãƒ¼ãƒ‰ =========================
if mode == "ğŸ“Š å¯è¦–åŒ–":
    st.header("DB å¯è¦–åŒ–")

    # 1) åº—èˆ—ãƒªã‚¹ãƒˆ
    with eng.connect() as conn:
        stores = [r[0] for r in conn.execute(sa.text(
            "SELECT tablename FROM pg_tables WHERE tablename LIKE 'slot_%'"))]
    if not stores:
        st.info("ã¾ãšå–ã‚Šè¾¼ã¿ãƒ¢ãƒ¼ãƒ‰ã§ãƒ‡ãƒ¼ã‚¿ã‚’å…¥ã‚Œã¦ãã ã•ã„ã€‚")
        st.stop()

    store_sel = st.selectbox("åº—èˆ—", stores)
    tbl = sa.Table(store_sel, sa.MetaData(), autoload_with=eng)

    # 2) æ—¥ä»˜ãƒ¬ãƒ³ã‚¸
    c1, c2 = st.columns(2)
    vis_start = c1.date_input("é–‹å§‹æ—¥", value=dt.date(2025, 1, 1))
    vis_end   = c2.date_input("çµ‚äº†æ—¥", value=dt.date.today())

    # 3) æ©Ÿç¨®é¸æŠ
    q_machine = sa.select(tbl.c.æ©Ÿç¨®).where(tbl.c.date.between(vis_start, vis_end)).distinct()
    with eng.connect() as conn:
        machines = [r[0] for r in conn.execute(q_machine)]
    if not machines:
        st.warning("æŒ‡å®šæœŸé–“ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"); st.stop()
    machine_sel = st.selectbox("æ©Ÿç¨®", machines)

    # 4) å°ç•ªå·é¸æŠ
    q_slot = sa.select(tbl.c.å°ç•ªå·).where(
        tbl.c.æ©Ÿç¨® == machine_sel,
        tbl.c.date.between(vis_start, vis_end)
    ).distinct().order_by(tbl.c.å°ç•ªå·)
    with eng.connect() as conn:
        slots = [r[0] for r in conn.execute(q_slot)]
    if not slots:
        st.warning("ã“ã®æ©Ÿç¨®ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"); st.stop()
    slot_sel = st.selectbox("å°ç•ªå·", slots)

    # 5) ãƒ‡ãƒ¼ã‚¿å–å¾—
    sql = sa.select(tbl).where(
        tbl.c.date.between(vis_start, vis_end),
        tbl.c.æ©Ÿç¨® == machine_sel,
        tbl.c.å°ç•ªå· == slot_sel
    ).order_by(tbl.c.date)
    df = pd.read_sql(sql, eng)
    if df.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“"); st.stop()

    # 6) è¡¨ç¤ºå½¢å¼é¸æŠ
    fmt = st.radio("è¡¨ç¤ºå½¢å¼", ("å°æ•° (0.003)", "% è¡¨ç¤º", "1/â—¯ è¡¨ç¤º"), horizontal=True)

    df_plot = df.copy()
    if fmt == "% è¡¨ç¤º":
        df_plot["plot_val"] = df_plot["åˆæˆç¢ºç‡"] * 100     # 0-1 â†’ 0-100
        y_axis = alt.Axis(title="åˆæˆç¢ºç‡ (%)")
        tooltip_fmt = ".2f"
    elif fmt == "1/â—¯ è¡¨ç¤º":
        df_plot["plot_val"] = df_plot["åˆæˆç¢ºç‡"].replace(0, pd.NA).rdiv(1)
        y_axis = alt.Axis(title="1 / åˆæˆç¢ºç‡")
        tooltip_fmt = ".0f"
    else:  # å°æ•°
        df_plot["plot_val"] = df_plot["åˆæˆç¢ºç‡"]
        y_axis = alt.Axis(title="åˆæˆç¢ºç‡ (å°æ•°)")
        tooltip_fmt = ".4f"

    # 7) æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•
    st.subheader(f"ğŸ“ˆ åˆæˆç¢ºç‡ | {machine_sel} | å° {slot_sel}")
    chart = alt.Chart(df_plot).mark_line().encode(
        x="date:T",
        y=alt.Y("plot_val:Q", axis=y_axis),
        tooltip=["date", alt.Tooltip("plot_val:Q", title="å€¤", format=tooltip_fmt)]
    ).properties(height=300)
    st.altair_chart(chart, use_container_width=True)

