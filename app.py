import io, datetime as dt, pandas as pd, streamlit as st
import sqlalchemy as sa
from sqlalchemy.dialects.postgresql import insert as pg_insert
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
import altair as alt
import json

# -------- è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ --------
with open("setting.json", encoding="utf-8") as f:
    setting_map = json.load(f)

st.set_page_config(page_title="Slot Manager", layout="wide")
mode = st.sidebar.radio("ãƒ¢ãƒ¼ãƒ‰", ("ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿", "ğŸ“Š å¯è¦–åŒ–"))
st.title("ğŸ° Slot Data Manager & Visualizer")

SA_INFO = st.secrets["gcp_service_account"]
PG_CFG  = st.secrets["connections"]["slot_db"]

# -------- Drive, DB æ¥ç¶š --------
@st.cache_resource
def gdrive():
    try:
        creds = Credentials.from_service_account_info(
            SA_INFO, scopes=["https://www.googleapis.com/auth/drive.readonly"]
        )
        return build("drive", "v3", credentials=creds)
    except Exception as e:
        st.error(f"Driveèªè¨¼ã‚¨ãƒ©ãƒ¼: {e}")
        return None
drive = gdrive()

@st.cache_resource
def engine():
    try:
        url = (
            f"postgresql+psycopg2://{PG_CFG.username}:{PG_CFG.password}"
            f"@{PG_CFG.host}:{PG_CFG.port}/{PG_CFG.database}?sslmode=require"
        )
        return sa.create_engine(url, pool_pre_ping=True)
    except Exception as e:
        st.error(f"DBæ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None
eng = engine()

# -------- ãƒ†ãƒ¼ãƒ–ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ --------
@st.cache_resource
def get_table(table_name: str) -> sa.Table:
    try:
        meta = sa.MetaData()
        return sa.Table(table_name, meta, autoload_with=eng)
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—ã‚¨ãƒ©ãƒ¼ ({table_name}): {e}")
        raise

# -------- å®šç¾©ãƒãƒƒãƒ”ãƒ³ã‚° --------
COLUMN_MAP = {
    "ãƒ¡ãƒƒã‚»æ­¦è”µå¢ƒ": {
        "å°ç•ªå·":"å°ç•ªå·","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ",
        "BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°","ARTå›æ•°":"ARTå›æ•°","æœ€å¤§æŒã¡ç‰":"æœ€å¤§æŒç‰",
        "BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","ARTç¢ºç‡":"ARTç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ",
    },
    "ã‚¸ãƒ£ãƒ³ã‚¸ãƒ£ãƒ³ãƒãƒ¼ãƒ«ã‚´ãƒƒãƒˆåˆ†å€æ²³åŸ":{
        "å°ç•ªå·":"å°ç•ªå·","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ","BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°",
        "æœ€å¤§æŒã¡ç‰":"æœ€å¤§æŒç‰","BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°",
    },
    "ãƒ—ãƒ¬ã‚´ç«‹å·":{
        "å°ç•ªå·":"å°ç•ªå·","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ":"ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ","BBå›æ•°":"BBå›æ•°","RBå›æ•°":"RBå›æ•°",
        "æœ€å¤§å·®ç‰":"æœ€å¤§å·®ç‰","BBç¢ºç‡":"BBç¢ºç‡","RBç¢ºç‡":"RBç¢ºç‡","åˆæˆç¢ºç‡":"åˆæˆç¢ºç‡",
        "å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ":"å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°":"ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°",
    },
}

# -------- ãƒ•ã‚¡ã‚¤ãƒ«åˆ—æŒ™ --------
def list_csv_recursive(folder_id: str):
    all_files, queue = [], [(folder_id, "")]
    while queue:
        fid, cur = queue.pop()
        res = drive.files().list(
            q=f"'{fid}' in parents and trashed=false",
            fields="files(id,name,mimeType)", pageSize=1000
        ).execute()
        for f in res.get("files", []):
            if f["mimeType"] == "application/vnd.google-apps.folder":
                queue.append((f["id"], f"{cur}/{f['name']}"))
            elif f["name"].lower().endswith(".csv"):
                all_files.append({**f, "path": f"{cur}/{f['name']}"})
    return all_files

# -------- æ­£è¦åŒ– --------
def normalize(df_raw: pd.DataFrame, store: str) -> pd.DataFrame:
    df = df_raw.rename(columns=COLUMN_MAP[store])
    prob_cols = ["BBç¢ºç‡","RBç¢ºç‡","ARTç¢ºç‡","åˆæˆç¢ºç‡"]
    for col in prob_cols:
        if col not in df.columns: continue
        ser = df[col].astype(str)
        mask_div = ser.str.contains("/")
        if mask_div.any():
            denom = ser[mask_div].str.split("/", expand=True)[1].astype(float)
            df.loc[mask_div,col] = denom.where(denom!=0, pd.NA).rdiv(1.0).fillna(0)
        num = pd.to_numeric(ser[~mask_div], errors="coerce")
        mask_gt1 = num>1
        num.loc[mask_gt1] = 1.0/num.loc[mask_gt1]
        df.loc[~mask_div,col] = num
        df[col] = df[col].astype(float)
    int_cols=["å°ç•ªå·","ç´¯è¨ˆã‚¹ã‚¿ãƒ¼ãƒˆ","ã‚¹ã‚¿ãƒ¼ãƒˆå›æ•°","BBå›æ•°","RBå›æ•°","ARTå›æ•°","æœ€å¤§æŒã¡ç‰","æœ€å¤§å·®ç‰","å‰æ—¥æœ€çµ‚ã‚¹ã‚¿ãƒ¼ãƒˆ"]
    for col in int_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col],errors="coerce").astype("Int64")
    return df

# -------- ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä»˜ãèª­ã¿è¾¼ã¿ï¼‹æ­£è¦åŒ– --------
@st.cache_data
def load_and_normalize(raw_bytes: bytes, store: str) -> pd.DataFrame:
    df_raw = pd.read_csv(io.BytesIO(raw_bytes), encoding="shift_jis", on_bad_lines="skip")
    return normalize(df_raw, store)

# -------- ãƒ¡ã‚¿æƒ…å ±è§£æ --------
def parse_meta(path: str):
    parts=path.strip("/").split("/")
    store,machine,date=parts[-3],parts[-2],dt.date.fromisoformat(parts[-1][-14:-4])
    return store,machine,date

# -------- ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ --------
def ensure_store_table(store: str):
    safe="slot_"+store.replace(" ","_")
    meta=sa.MetaData()
    if not eng.dialect.has_table(eng.connect(),safe):
        cols=[sa.Column("date",sa.Date),sa.Column("æ©Ÿç¨®",sa.Text)]
        for col in COLUMN_MAP[store].values(): cols.append(sa.Column(col,sa.Double,nullable=True))
        cols.append(sa.PrimaryKeyConstraint("date","æ©Ÿç¨®","å°ç•ªå·"))
        sa.Table(safe,meta,*cols)
        meta.create_all(eng)
    return sa.Table(safe,meta,autoload_with=eng)

# ========================= ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿ =========================
if mode=="ğŸ“¥ ãƒ‡ãƒ¼ã‚¿å–ã‚Šè¾¼ã¿":
    st.header("Google Drive â†’ Postgres ã‚¤ãƒ³ãƒãƒ¼ãƒˆ")
    folder_options={"ğŸ§ª ãƒ†ã‚¹ãƒˆç”¨":"1MRQFPBahlSwdwhrqqBzudXL18y8-qOb8","ğŸš€ æœ¬ç•ªç”¨":"1hX8GQRuDm_E1A1Cu_fZudXL18y8-qOb8"}
    sel_label=st.selectbox("ãƒ•ã‚©ãƒ«ãƒ€ã‚¿ã‚¤ãƒ—",list(folder_options.keys()))
    folder_id=st.text_input("Google Drive ãƒ•ã‚©ãƒ«ãƒ€ ID",value=folder_options[sel_label])
    c1,c2=st.columns(2)
    imp_start=c1.date_input("é–‹å§‹æ—¥",dt.date(2024,1,1))
    imp_end=c2.date_input("çµ‚äº†æ—¥",dt.date.today())
    if st.button("ğŸš€ ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Ÿè¡Œ",disabled=not folder_id):
        try:
            files=[f for f in list_csv_recursive(folder_id) if imp_start<=parse_meta(f['path'])[2]<=imp_end]
        except Exception as e:
            st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            st.stop()
        st.write(f"ğŸ” å¯¾è±¡ CSV: **{len(files)} ä»¶**")
        bar=st.progress(0.0)
        current_file = st.empty()  # å‡¦ç†ä¸­ãƒ•ã‚¡ã‚¤ãƒ«åè¡¨ç¤ºç”¨ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€
        for i,f in enumerate(files,1):
            current_file.text(f"å‡¦ç†ä¸­ãƒ•ã‚¡ã‚¤ãƒ«: {f['path']}")
            try:
                raw=drive.files().get_media(fileId=f['id']).execute()
                store,machine,date=parse_meta(f['path'])
                df=load_and_normalize(raw,store)
                if df.empty: continue
                tbl=ensure_store_table(store)
                df['æ©Ÿç¨®'],df['date']=machine,date
                df=df[[c for c in df.columns if c in tbl.c.keys()]]
                stmt=pg_insert(tbl).values(df.to_dict('records')).on_conflict_do_nothing()
                with eng.begin() as conn: conn.execute(stmt)
            except Exception as e:
                st.error(f"{f['path']} å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
            bar.progress(i/len(files))
        current_file.text("")  # å‡¦ç†å®Œäº†å¾Œã¯æ¶ˆå»
        st.success("ã‚¤ãƒ³ãƒãƒ¼ãƒˆå®Œäº†ï¼")

# ========================= å¯è¦–åŒ–ãƒ¢ãƒ¼ãƒ‰ =========================
if mode=="ğŸ“Š å¯è¦–åŒ–":
    st.header("DB å¯è¦–åŒ–")
    try:
        tables=[r[0] for r in eng.connect().execute(sa.text("SELECT tablename FROM pg_tables WHERE tablename LIKE 'slot_%'"))]
    except Exception as e:
        st.error(f"ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    table_name=st.selectbox("ãƒ†ãƒ¼ãƒ–ãƒ«é¸æŠ",tables)
    tbl=get_table(table_name)
    c1,c2=st.columns(2)
    vis_start=c1.date_input("é–‹å§‹æ—¥",dt.date(2024,1,1))
    vis_end=c2.date_input("çµ‚äº†æ—¥",dt.date.today())
    try:
        machines=[r[0] for r in eng.connect().execute(sa.select(tbl.c.æ©Ÿç¨®).where(tbl.c.date.between(vis_start,vis_end)).distinct())]
    except Exception as e:
        st.error(f"æ©Ÿç¨®å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    machine_sel=st.selectbox("æ©Ÿç¨®é¸æŠ",machines)
    try:
        df=pd.read_sql(sa.select(tbl).where(tbl.c.æ©Ÿç¨®==machine_sel, tbl.c.date.between(vis_start,vis_end)).order_by(tbl.c.date),eng)
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        st.stop()
    if df.empty:
        st.warning("ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        st.stop()
    # ãƒ—ãƒ­ãƒƒãƒˆç”¨æ•´å½¢
    if st.sidebar.checkbox("å…¨å°å¹³å‡ã‚’è¡¨ç¤º",value=False):
        df_plot=df.groupby('date')['åˆæˆç¢ºç‡'].mean().reset_index().rename(columns={'åˆæˆç¢ºç‡':'plot_val'})
        title=f"ğŸ“ˆ å…¨å°å¹³å‡ åˆæˆç¢ºç‡ | {machine_sel}"
    else:
        slots=[int(r[0]) for r in eng.connect().execute(sa.select(tbl.c.å°ç•ªå·).where(tbl.c.æ©Ÿç¨®==machine_sel, tbl.c.date.between(vis_start,vis_end)).distinct().order_by(tbl.c.å°ç•ªå·)) if r[0] is not None]
        slot_sel=st.selectbox("å°ç•ªå·",slots)
        df_plot=df[df['å°ç•ªå·']==slot_sel].rename(columns={'åˆæˆç¢ºç‡':'plot_val'})
        title=f"ğŸ“ˆ åˆæˆç¢ºç‡ | {machine_sel} | å° {slot_sel}"
    # é–¾å€¤ãƒ©ã‚¤ãƒ³
    thresholds=setting_map.get(machine_sel,{})
    df_rules=pd.DataFrame([{'setting':k,'value':v} for k,v in thresholds.items()])
    # å‡¡ä¾‹ãƒˆã‚°ãƒ«
    legend_sel=alt.selection_multi(fields=['setting'], bind='legend')
    y_axis=alt.Axis(title='åˆæˆç¢ºç‡',format='.4f',labelExpr=("datum.value==0?'0':'1/'+format(round(1/datum.value),'d')"))
    base=alt.Chart(df_plot).mark_line().encode(x='date:T',y=alt.Y('plot_val:Q',axis=y_axis),tooltip=['date',alt.Tooltip('plot_val:Q',title='å€¤',format='.4f')]).properties(height=400)
    rules=alt.Chart(df_rules).mark_rule(strokeDash=[4,2]).encode(y='value:Q',color=alt.Color('setting:N',legend=alt.Legend(title='è¨­å®š')),opacity=alt.condition(legend_sel,alt.value(1),alt.value(0))).add_selection(legend_sel)
    st.subheader(title)
    st.altair_chart(base+rules,use_container_width=True)
